{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acceso al archivo de datos y asignación a un dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceso al archivo csv y asignación a un dataframe \n",
    "#ETL 1\n",
    "df_vfed = pd.read_csv('../sources/Vehicle Fuel Economy Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETL 2\n",
    "df = pd.read_csv('../sources/costo_operacional_vehiculos.csv')\n",
    "df_crp = pd.read_csv('../sources/car_resale_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceso al archivo parquet y asignación a un dataframe \n",
    "#ETL 3\n",
    "df_yellow_tripdata = pd.read_parquet('..\\sources\\yellow_tripdata_2024-01.parquet')\n",
    "df_green_tripdata = pd.read_parquet('..\\sources\\green_tripdata_2024-01.parquet')\n",
    "df_fhv_tripdata = pd.read_parquet('..\\sources\\\\fhv_tripdata_2024-01.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de la información del Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df_yellow_tripdata.info()\n",
    "df_green_tripdata.info()\n",
    "df_fhv_tripdata.info()\n",
    "df_vfed.info()\n",
    "df_crp.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de los Datos Iniciales del Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vfed.head()\n",
    "df.head()\n",
    "df_yellow_tripdata.head()\n",
    "df_green_tripdata.head()\n",
    "df_fhv_tripdata.head()\n",
    "df_crp.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de los Datos Finales del Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vfed.tail()\n",
    "df.tail()\n",
    "df_yellow_tripdata.tail()\n",
    "df_green_tripdata.tail()\n",
    "df_fhv_tripdata.tail()\n",
    "df_crp.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mantener columnas necesarias en el Dataframe\n",
    "\n",
    "Se recomienda usar el metodo drop ya que el dataframe original se va a usar modificandolo y no es necesario crear un dataframe nuevo que consume memoria y es menos eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETL1\n",
    "#  Eliminación de columnas no necesarias\n",
    "df_vfed_col_eli = ['barrelsA08','charge240','fuelType','barrels08','range',\n",
    "       'city08U','cityA08','cityA08U','cityCD','cityE','cityUF',\n",
    "       'comb08', 'comb08U','combA08', 'combA08U', 'combE', 'combinedCD', 'combinedUF',\n",
    "       'cylinders','displ', 'drive', 'engId', 'eng_dscr', 'feScore',\n",
    "       'ghgScore', 'ghgScoreA','co2A', 'co2TailpipeAGpm', 'co2TailpipeGpm',\n",
    "       'highway08', 'highway08U', 'highwayA08', 'highwayA08U',\n",
    "       'highwayCD', 'highwayE', 'highwayUF', 'hlv', 'hpv', 'id', 'lv2', 'lv4',\n",
    "       'mpgData', 'phevBlended', 'pv2', 'pv4','rangeCity',\n",
    "       'rangeCityA', 'rangeHwy', 'rangeHwyA', 'trany', 'UCity', 'UCityA',\n",
    "       'UHighway', 'UHighwayA', 'youSaveSpend', 'guzzler', 'trans_dscr',\n",
    "       'tCharger', 'sCharger', 'atvType', 'evMotor','rangeA',\n",
    "       'mfrCode', 'c240Dscr', 'charge240b', 'c240bDscr', 'createdOn',\n",
    "       'modifiedOn', 'startStop', 'phevCity', 'phevHwy', 'phevComb']\n",
    "df_vfed.drop(df_vfed_col_eli, axis=1, inplace=True)\n",
    "df_vfed = df_vfed.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL 2\n",
    "# Eliminar las columnas innecesarias\n",
    "columns_to_keep = ['Manuf', 'Model', 'Desc', 'Fuel_Type', 'Fuel_Cost', 'Electric_Cost', 'Total_Cost', 'Noise_Level']\n",
    "df_clean = df[columns_to_keep].copy()\n",
    "\n",
    "# Eliminar las columnas innecesarias\n",
    "df_crp.drop(['Unnamed: 0', 'engine_capacity', 'insurance', 'kms_driven', 'owner_type', \n",
    "         'seats', 'mileage', 'body_type', 'city'], axis=1, inplace=True)\n",
    "#df_crp = df_crp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renombrar Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL 1\n",
    "df_vfed.rename(columns={'city08':'Miles per gallon (mpg)','co2':'CO2 (p/mile)','fuelCost08':'FuelCost',\n",
    "                        'fuelCostA08':'FuelCostA','fuelType1':'Fuel',\n",
    "                        'VClass':'Category','fuelType2':'Alternative Fuel'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificar valores de las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL 1\n",
    "# Cambiamos NaN del Combustible Alternativo a No\n",
    "df_vfed['Alternative Fuel'] = df_vfed['Alternative Fuel'].fillna('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL 2\n",
    "# Eliminar el símbolo de libra y convertir las columnas de costos a numéricas\n",
    "df_clean['Fuel_Cost'] = df_clean['Fuel_Cost'].replace('[£,]', '', regex=True).astype(float)\n",
    "df_clean['Electric_Cost'] = df_clean['Electric_Cost'].replace('[£,]', '', regex=True).astype(float)\n",
    "df_clean['Total_Cost'] = df_clean['Total_Cost'].replace('[£,]', '', regex=True).astype(float)\n",
    "\n",
    "# Asumamos una tasa de conversión de 1 libra esterlina = 1.17 euros y 1 euro = 1.10 dólares\n",
    "gbp_to_eur = 1.17\n",
    "eur_to_usd = 1.10\n",
    "\n",
    "# Convertir los costos de libras a euros y luego a dólares\n",
    "df_clean['Fuel_Cost'] = df_clean['Fuel_Cost'] * gbp_to_eur * eur_to_usd\n",
    "df_clean['Electric_Cost'] = df_clean['Electric_Cost'] * gbp_to_eur * eur_to_usd\n",
    "df_clean['Total_Cost'] = df_clean['Total_Cost'] * gbp_to_eur * eur_to_usd\n",
    "\n",
    "# Factor de conversión de millas a kilómetros\n",
    "miles_to_km = 1.60934\n",
    "\n",
    "# Ajustar los costos de 10,000 millas a 10,000 kilómetros\n",
    "conversion_factor = 10000 / (10000 * miles_to_km)\n",
    "\n",
    "df_clean['Fuel_Cost'] *= conversion_factor\n",
    "df_clean['Electric_Cost'] *= conversion_factor\n",
    "df_clean['Total_Cost'] *= conversion_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en 'registered_year' después de la conversión: <IntegerArray>\n",
      "[2017, 2018, 2015, 2009, 2010, 2016, 2014, 2020, 2021, 2019, 2011, 2012, 2013,\n",
      " 2022, 2004, <NA>, 2008, 2006, 2023, 2003, 2007, 2002, 2005]\n",
      "Length: 23, dtype: Int64\n",
      "                      full_name  resale_price  registered_year  \\\n",
      "0  2017 Maruti Baleno 1.2 Alpha        6540.0             2017   \n",
      "1            2018 Tata Hexa XTA       12000.0             2018   \n",
      "2   2015 Maruti Swift Dzire VXI        5400.0             2015   \n",
      "3   2015 Maruti Swift Dzire VXI        5400.0             2015   \n",
      "4    2009 Hyundai i10 Magna 1.1        1920.0             2009   \n",
      "\n",
      "  transmission_type fuel_type  max_power  \n",
      "0            Manual    Petrol    83.1bhp  \n",
      "1         Automatic    Diesel  153.86bhp  \n",
      "2            Manual    Petrol   83.14bhp  \n",
      "3            Manual    Petrol   83.14bhp  \n",
      "4            Manual    Petrol   68.05bhp  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "# ETL 2\n",
    "# 1. Asegurarnos de que no haya valores NaN y eliminar el símbolo '₹' y las comas\n",
    "df_crp['resale_price'] = df_crp['resale_price'].str.replace('₹', '', regex=False)\n",
    "df_crp['resale_price'] = df_crp['resale_price'].str.replace(',', '', regex=False)\n",
    "\n",
    "# 2. Convertir los valores que contienen \"Lakh\" a su valor numérico\n",
    "def convert_lakh_to_numeric(price_str):\n",
    "    if 'Lakh' in price_str:\n",
    "        number = re.findall(r'\\d+\\.\\d+|\\d+', price_str)[0]\n",
    "        return float(number) * 100000\n",
    "    return None\n",
    "\n",
    "df_crp['resale_price'] = df_crp['resale_price'].apply(lambda x: convert_lakh_to_numeric(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Asignamos el tipo de cambio correcto de Rupias a Dólares\n",
    "conversion_rate = 0.012\n",
    "df_crp['resale_price'] = df_crp['resale_price'] * conversion_rate\n",
    "\n",
    "# Eliminar las columnas 'resale_price' y 'resale_price_cleaned'\n",
    "#df.drop(['resale_price', 'resale_price_cleaned'], axis=1, inplace=True)\n",
    "\n",
    "# Renombrar la columna 'resale_price_usd' a 'resale_price'\n",
    "#df.rename(columns={'resale_price_usd': 'resale_price'}, inplace=True)\n",
    "\n",
    "# Eliminar las columnas innecesarias\n",
    "#df.drop(['Unnamed: 0', 'engine_capacity', 'insurance', 'kms_driven', 'owner_type', \n",
    "#         'seats', 'mileage', 'body_type', 'city'], axis=1, inplace=True)\n",
    "\n",
    "# Asegurarse de que la columna 'resale_price' esté en formato numérico\n",
    "df_crp['resale_price'] = pd.to_numeric(df_crp['resale_price'], errors='coerce')\n",
    "df_crp['resale_price'] = df_crp['resale_price'].round(2)\n",
    "\n",
    "# Función para extraer solo el año\n",
    "def extract_year(value):\n",
    "    if pd.isnull(value):\n",
    "        return None\n",
    "    match = re.search(r'\\b(19|20)\\d{2}\\b', str(value))\n",
    "    if match:\n",
    "        return int(match.group(0))\n",
    "    return None\n",
    "\n",
    "# Función para extraer solo el año\n",
    "def extract_year(value):\n",
    "    if pd.isnull(value):\n",
    "        return None\n",
    "    match = re.search(r'\\b(19|20)\\d{2}\\b', str(value))\n",
    "    if match:\n",
    "        return int(match.group(0))\n",
    "    return None\n",
    "\n",
    "# Limpiar la columna 'registered_year' para extraer solo los años\n",
    "df_crp['registered_year'] = df_crp['registered_year'].apply(extract_year)\n",
    "\n",
    "# Convertir 'registered_year' a enteros, manejando valores nulos\n",
    "df_crp['registered_year'] = df_crp['registered_year'].astype('Int64')  # Usar tipo de datos Int64 para manejar NaN\n",
    "df_crp['registered_year'] = df_crp['registered_year'].fillna(pd.NA)  # Mantener NaN si es necesario\n",
    "\n",
    "# Verificar los valores únicos después de la conversión\n",
    "print(\"Valores únicos en 'registered_year' después de la conversión:\", df_crp['registered_year'].unique())\n",
    "\n",
    "# Verificar el DataFrame después de la conversión\n",
    "print(df_crp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL 3\n",
    "# Transformaciones adicionales (ejemplo: convertir formatos de fecha)\n",
    "if 'pickup_datetime' in df_fhv_tripdata.columns:\n",
    "    df_fhv_tripdata['pickup_datetime'] = pd.to_datetime(df_fhv_tripdata['pickup_datetime'])\n",
    "if 'dropoff_datetime' in df_fhv_tripdata.columns:\n",
    "    df_fhv_tripdata['dropoff_datetime'] = pd.to_datetime(df_fhv_tripdata['dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificar filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETL 1\n",
    "# Eliminamos las filas donde 'Fuel' es nulo\n",
    "df_vfed = df_vfed[df_vfed['Fuel'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETL 1\n",
    "# Eliminamos las filas con duplicados\n",
    "df_vfed = df_vfed.drop_duplicates()\n",
    "df_vfed.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETL 2\n",
    "# Eliminar duplicados (mantener la última ocurrencia)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "df_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_crp = df_crp.drop_duplicates()\n",
    "df_crp.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL 3\n",
    "# Limpiar datos: eliminar duplicados\n",
    "df_yellow_tripdata = df_yellow_tripdata.drop_duplicates()\n",
    "df_yellow_tripdata.reset_index(drop=True, inplace=True)\n",
    "df_green_tripdata = df_green_tripdata.drop_duplicates()\n",
    "df_green_tripdata.reset_index(drop=True, inplace=True)\n",
    "df_fhv_tripdata = df_green_tripdata.drop_duplicates()\n",
    "df_fhv_tripdata.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar el Dataframe en la carpeta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETL 1\n",
    "# Guarda el dataframe en la carpeta Data\n",
    "df_vfed.to_parquet('../Data/df_vfed.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETL 2\n",
    "# Guarda el dataframe en la carpeta Data\n",
    "df_clean.to_csv('../Data/costo_operacional_vehiculos_clean.csv', index=False)\n",
    "\n",
    "# Guardar el DataFrame limpio\n",
    "df_crp.to_csv('../Data/car_resale_prices_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETL 3\n",
    "# Guarda el dataframe en la carpeta Data\n",
    "df_yellow_tripdata.to_parquet('../Data/cleaned_yellow_tripdata_2024-01.parquet', index=False)\n",
    "df_green_tripdata.to_parquet('../Data/cleaned_green_tripdata_2024-01.parquet', index=False)\n",
    "df_fhv_tripdata.to_parquet('../Data/cleaned_fhv_tripdata_2024-01.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por una cuestion de tamaño que GitHub recomienda no subir archivos que pesen mas de 50mb, dividimos el archivo en 5 partes para luego en el EDA unirlos y seguir trabajando sin problemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETL 3\n",
    "import numpy as np\n",
    "\n",
    "# Leer el archivo parquet\n",
    "df = pd.read_parquet('../Data/cleaned_yellow_tripdata_2024-01.parquet')\n",
    "\n",
    "# Número de partes en las que quieres dividir el DataFrame\n",
    "num_parts = 5  # Cambia esto según el número de partes que desees\n",
    "\n",
    "# Dividir el DataFrame en partes iguales\n",
    "chunks = np.array_split(df, num_parts)\n",
    "\n",
    "# Guardar cada parte en un archivo parquet separado\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.to_parquet(f'../Data/cleaned_yellow_tripdata_part_{i+1}.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificación de Archivos Generados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_yellow_tripdata_part_1.parquet\n",
      "cleaned_yellow_tripdata_part_2.parquet\n",
      "cleaned_yellow_tripdata_part_3.parquet\n",
      "cleaned_yellow_tripdata_part_4.parquet\n",
      "cleaned_yellow_tripdata_part_5.parquet\n"
     ]
    }
   ],
   "source": [
    "#ETL 3\n",
    "import os\n",
    "\n",
    "# Verifica los archivos generados\n",
    "for filename in os.listdir('../Data'):\n",
    "    if filename.startswith('cleaned_yellow_tripdata_part_') and filename.endswith('.parquet'):\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminación de Archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo \"../Data/cleaned_yellow_tripdata_2024-01.parquet\" eliminado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "#ETL 3\n",
    "# Eliminar el archivo\n",
    "if os.path.exists('../Data/cleaned_yellow_tripdata_2024-01.parquet'):\n",
    "    os.remove('../Data/cleaned_yellow_tripdata_2024-01.parquet')\n",
    "    print(f'Archivo \"../Data/cleaned_yellow_tripdata_2024-01.parquet\" eliminado exitosamente.')\n",
    "else:\n",
    "    print(f'El archivo \"../Data/cleaned_yellow_tripdata_2024-01.parquet\" no existe.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
